{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrieval_gt</th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>generation_gt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[c68a1103-7cb5-4f86-a46a-5f75fb88cfc2]]</td>\n",
       "      <td>4ce77353-5441-4d2d-94e4-e837fcb19e25</td>\n",
       "      <td>일본 정부가 AI 위험을 줄이기 위해 어떤 조치를 취했나요?</td>\n",
       "      <td>[일본 정부는 AI 위험을 줄이기 위해 기술적 해결책을 중요시하며, AI 글로벌 파...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[d55e6e70-8741-4063-9c1d-cc7357b9c268]]</td>\n",
       "      <td>4ec41559-67d1-45aa-858e-9747b6fb6bbd</td>\n",
       "      <td>마이크로소프트가 프랑스에 투자한 금액은 얼마인가요?</td>\n",
       "      <td>[마이크로소프트가 프랑스에 투자한 금액은 40억 유로입니다.]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[61097ef9-739d-488a-9ce4-802433a349ba]]</td>\n",
       "      <td>fc74a5be-098b-4563-9bbe-bd1fc23f45df</td>\n",
       "      <td>ICML 2025 행사에서 다루는 주요 영역은 무엇인가요?</td>\n",
       "      <td>[ICML 2025 행사에서는 머신러닝, 딥러닝, 최적화, 신뢰할 수 있는 머신러닝...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[581b4311-2236-44dd-80b0-e02c6906984b]]</td>\n",
       "      <td>14408056-937f-44a1-878e-e73c3b5b5f09</td>\n",
       "      <td>구글이 AI 기회 기금의 1차 수혜자로 선정한 단체는 무엇인가요?</td>\n",
       "      <td>[구글이 AI 기회 기금의 1차 수혜자로 선정한 단체는 재향군인 ·군인가족협회와 굿...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[db2b35e9-4f60-400b-bcf2-6443e978f621]]</td>\n",
       "      <td>68713781-37e8-44ac-ab49-8e57b9402aec</td>\n",
       "      <td>GPT-4o는 어떤 성능을 보여주었나요?</td>\n",
       "      <td>[GPT-4o는 GPT-4 터보와 동일한 성능을 보여주었으며, 다국어, 오디오, 이...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               retrieval_gt  \\\n",
       "0  [[c68a1103-7cb5-4f86-a46a-5f75fb88cfc2]]   \n",
       "1  [[d55e6e70-8741-4063-9c1d-cc7357b9c268]]   \n",
       "2  [[61097ef9-739d-488a-9ce4-802433a349ba]]   \n",
       "3  [[581b4311-2236-44dd-80b0-e02c6906984b]]   \n",
       "4  [[db2b35e9-4f60-400b-bcf2-6443e978f621]]   \n",
       "\n",
       "                                    qid                                 query  \\\n",
       "0  4ce77353-5441-4d2d-94e4-e837fcb19e25     일본 정부가 AI 위험을 줄이기 위해 어떤 조치를 취했나요?   \n",
       "1  4ec41559-67d1-45aa-858e-9747b6fb6bbd          마이크로소프트가 프랑스에 투자한 금액은 얼마인가요?   \n",
       "2  fc74a5be-098b-4563-9bbe-bd1fc23f45df      ICML 2025 행사에서 다루는 주요 영역은 무엇인가요?   \n",
       "3  14408056-937f-44a1-878e-e73c3b5b5f09  구글이 AI 기회 기금의 1차 수혜자로 선정한 단체는 무엇인가요?   \n",
       "4  68713781-37e8-44ac-ab49-8e57b9402aec                GPT-4o는 어떤 성능을 보여주었나요?   \n",
       "\n",
       "                                       generation_gt  \n",
       "0  [일본 정부는 AI 위험을 줄이기 위해 기술적 해결책을 중요시하며, AI 글로벌 파...  \n",
       "1                 [마이크로소프트가 프랑스에 투자한 금액은 40억 유로입니다.]  \n",
       "2  [ICML 2025 행사에서는 머신러닝, 딥러닝, 최적화, 신뢰할 수 있는 머신러닝...  \n",
       "3  [구글이 AI 기회 기금의 1차 수혜자로 선정한 단체는 재향군인 ·군인가족협회와 굿...  \n",
       "4  [GPT-4o는 GPT-4 터보와 동일한 성능을 보여주었으며, 다국어, 오디오, 이...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df = pd.read_parquet(\"../korean_embedding/data/qa.parquet\")\n",
    "qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>일본 정부가 AI 위험을 줄이기 위해 어떤 조치를 취했나요?</td>\n",
       "      <td>일본 정부는 AI 위험을 줄이기 위해 기술적 해결책을 중요시하며, AI 글로벌 파트...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>마이크로소프트가 프랑스에 투자한 금액은 얼마인가요?</td>\n",
       "      <td>마이크로소프트가 프랑스에 투자한 금액은 40억 유로입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ICML 2025 행사에서 다루는 주요 영역은 무엇인가요?</td>\n",
       "      <td>ICML 2025 행사에서는 머신러닝, 딥러닝, 최적화, 신뢰할 수 있는 머신러닝 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>구글이 AI 기회 기금의 1차 수혜자로 선정한 단체는 무엇인가요?</td>\n",
       "      <td>구글이 AI 기회 기금의 1차 수혜자로 선정한 단체는 재향군인 ·군인가족협회와 굿윌...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPT-4o는 어떤 성능을 보여주었나요?</td>\n",
       "      <td>GPT-4o는 GPT-4 터보와 동일한 성능을 보여주었으며, 다국어, 오디오, 이미...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               question  \\\n",
       "0     일본 정부가 AI 위험을 줄이기 위해 어떤 조치를 취했나요?   \n",
       "1          마이크로소프트가 프랑스에 투자한 금액은 얼마인가요?   \n",
       "2      ICML 2025 행사에서 다루는 주요 영역은 무엇인가요?   \n",
       "3  구글이 AI 기회 기금의 1차 수혜자로 선정한 단체는 무엇인가요?   \n",
       "4                GPT-4o는 어떤 성능을 보여주었나요?   \n",
       "\n",
       "                                        ground_truth  \n",
       "0  일본 정부는 AI 위험을 줄이기 위해 기술적 해결책을 중요시하며, AI 글로벌 파트...  \n",
       "1                   마이크로소프트가 프랑스에 투자한 금액은 40억 유로입니다.  \n",
       "2  ICML 2025 행사에서는 머신러닝, 딥러닝, 최적화, 신뢰할 수 있는 머신러닝 ...  \n",
       "3  구글이 AI 기회 기금의 1차 수혜자로 선정한 단체는 재향군인 ·군인가족협회와 굿윌...  \n",
       "4  GPT-4o는 GPT-4 터보와 동일한 성능을 보여주었으며, 다국어, 오디오, 이미...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df = qa_df[[\"query\", \"generation_gt\"]]\n",
    "qa_df.columns = [\"question\", \"ground_truth\"]\n",
    "qa_df[\"ground_truth\"] = qa_df[\"ground_truth\"].apply(lambda x: x[0])\n",
    "qa_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anpigon/Library/Caches/pypoetry/virtualenvs/autorag-tutorial-ko-GYvpjDIx-py3.11/lib/python3.11/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-m3\"\n",
    "model_kwargs = {\"device\": \"mps\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": False}\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.retrievers import BM25Retriever\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "corpus_df = pd.read_parquet(\"../korean_embedding/data/corpus.parquet\")\n",
    "documents = [\n",
    "    Document(page_content=row[\"contents\"], metadata=row[\"metadata\"], id=row[\"doc_id\"])\n",
    "    for index, row in corpus_df.iterrows()\n",
    "]\n",
    "bm25_retriever = BM25Retriever.from_documents(documents)\n",
    "bm25_retriever.k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vectordb = Chroma(\n",
    "    persist_directory=\"../korean_embedding/benchmark_ollama/resources/chroma\",\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "vector_retriever = vectordb.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'creation_date': '2024-07-10', 'file_name': 'SPRi AI Brief_6월호_산업동향 최종.pdf', 'file_path': '/Users/anpigon/Workspace-ai/AutoRAG-tutorial-ko/99-Projects/korean_embedding/raw_docs/SPRi AI Brief_6월호_산업동향 최종.pdf', 'file_size': 4347658, 'file_type': 'application/pdf', 'last_modified_date': '2024-07-10', 'last_modified_datetime': datetime.datetime(2024, 7, 10, 1, 31, 20, 96983), 'next_id': None, 'page_label': '8', 'prev_id': '6d904c23-8262-4824-95f0-61064b530cc1'}, page_content='공통의 목적을 위해 협력할 것”이라고 설명\\n∙오픈AI의 샘 알트만 (Sam Altman) CEO는 온라인 행사에 참석해 글로벌 AI 거버넌스에서 히로시마 \\nAI 프로세스 하의 국제 지침과 행동 규범의 중요성을 강조하고 남반구 국가가 대거 참여한 프렌즈 \\n그룹의 역할에 기대감을 표시\\nn일본 정부는 AI 위험을 줄이기 위한 기술적 해결책도 중요하다는 점에서 도쿄에 국제협의체 ‘AI \\n글로벌 파트너십 (GPAI, Global Partnership on AI)’ 센터를 설립하고 기술 연구와 테스트를 \\n지원할 예정 \\n∙일본 정부는 생성 AI로 인한 허위 정보와 같은 위험을 해결하기 위해 콘텐츠 출처 검증 기술의 개발 \\n노력도 지원할 계획\\n☞ 출처:  Ministry of Foreign Affairs of Japan, Prime Minister Kishida’s attendance at the Side Event on Generative AI at \\nthe OECD Ministerial Council Meeting, 2024.05.02.\\n1) G7의 AI 국제 지침은 AI 수명주기 전반에 걸쳐 위험성 평가 및 위험 완화 조치를 요구하며 , 행동 규범은 첨단 AI 시스템 개발 \\n시 데이터 품질, 편향 완화, 기술적 보호조치 , 출처 추적 등 AI 개발과 배포시 고려해야 할 실질적 조치를 안내'),\n",
       " Document(metadata={'creation_date': '2024-07-10', 'file_name': 'SPRi AI Brief_6월호_산업동향 최종.pdf', 'file_path': '/Users/anpigon/Workspace-ai/AutoRAG-tutorial-ko/99-Projects/korean_embedding/raw_docs/SPRi AI Brief_6월호_산업동향 최종.pdf', 'file_size': 4347658, 'file_type': 'application/pdf', 'last_modified_date': '2024-07-10', 'last_modified_datetime': datetime.datetime(2024, 7, 10, 1, 31, 20, 96974), 'next_id': 'fcbb1a01-46fc-4699-96b5-7af77f97db4a', 'page_label': '4', 'prev_id': None}, page_content='1. 정책/법제  2. 기업/산업 3. 기술/연구  4. 인력/교육\\n1미국 백악관 , AI 행정명령 이후 180일 간 진행된 AI 조치 발표  \\nn미국 바이든 행정부는 AI 행정명령 발표 이후 180일 동안 연방정부 기관이 수행한 AI 위험 관리와 \\n소비자와 근로자 보호, 혁신 촉진과 인력 양성 조치를 개괄 \\nn연방정부 기관들은 AI로 인한 생화학 무기 위협과 주요기반시설 위협 대응, 근로자 보호 지침 \\n개발, 에너지 관리와 과학 연구에서 AI 활용, 연방정부 내 AI 인력 확충 등을 수행KEY Contents\\n£미국 연방 정부기관 , AI 위험관리와 근로자 ·소비자 보호, 혁신 촉진 등의 조치 이행 \\nn미국 백악관은 2024년 4월 29일 바이든 대통령의 AI 행정명령에 따라 연방정부 차원에서 180일간 \\n진행된 AI 조치를 개괄\\n∙2023년 10월 30일 발표된 AI 행정명령은 연방정부 기관들에게 AI의 안전과 위험 관리, 미국인의 개인정보 \\n보호 및 형평성과 시민권 증진, 소비자와 근로자 보호, 혁신 촉진, AI 인재 양성을 요구\\nn(AI 위험 관리) 연방정부 기관들은 AI로 인한 생화학 무기 위협과 주요기반시설 위협 대응, AI를 이용한  \\n소프트웨어  취약점 완화 등의 조치를 이행\\n∙백악관 과학기술정책국은 생화학 무기에 사용될 수 있는 위험한 생물학적 물질 개발에서 AI 오용을 막기 \\n위해 합성 핵산에 대한 선별 검사 프레임워크를 발표\\n∙국토안보부는 주요 기반시설 소유자와 운영자 대상의 AI 안전과 보안 지침을 개발하고 , 주요 기반시설에서  \\nAI의 안전한 개발과 배포를 보장할 AI안전보안이사회 (AI Safety and Security Board) 를 출범\\n∙국방부와 국토안보부가 주축이 되어 중요한 정부 소프트웨어 시스템에서 보안 취약점을 발견하고 \\n해결하기 위한 AI 도구를 시험  \\nn(근로자와 소비자 보호) AI가 근로자와 소비자 및 시민권에 미치는 위험을 완화하는 조치를'),\n",
       " Document(metadata={'creation_date': '2024-07-10', 'file_name': 'SPRi AI Brief_6월호_산업동향 최종.pdf', 'file_path': '/Users/anpigon/Workspace-ai/AutoRAG-tutorial-ko/99-Projects/korean_embedding/raw_docs/SPRi AI Brief_6월호_산업동향 최종.pdf', 'file_size': 4347658, 'file_type': 'application/pdf', 'last_modified_date': '2024-07-10', 'last_modified_datetime': datetime.datetime(2024, 7, 10, 1, 31, 20, 96995), 'next_id': 'd2617893-a48d-4fdd-adbc-f364c469fd53', 'page_label': '17', 'prev_id': None}, page_content='SPRi AI Brief |  2024-6 월호\\n14미국 국립표준기술연구소 , AI 위험 관리를 위한 4종의 지침 발간\\nn미국 국립표준기술연구소는 바이든 대통령의 AI 행정명령에 의거해 AI 시스템의 안전과 보안, \\n신뢰성 향상을 지원하기 위한 4종의 지침 초안을 발표\\nn4종의 지침은 △생성 AI의 위험요소와 위험 관리 조치 △학습 데이터의 위험 관리 △AI 합성 \\n콘텐츠의 위험 관리 △글로벌 차원의 AI 표준 수립과 관련된 내용을 포괄KEY Contents\\n£국립표준기술연구소 , 생성 AI·학습 데이터 ·합성 콘텐츠의 위험 관리를 위한 지침 발간\\nn미국 상무부 산하의 국립표준기술연구소 (NIST) 가 2024 년 4월 29일 AI 시스템의 안전과 보안, \\n신뢰성 향상을 지원하기 위한 4종의 지침 초안을 공개\\n∙NIST는 기술 업계에 AI 위험 완화를 요구한 바이든 대통령의 AI 행정명령에 따라 AI 위험을 \\n최소화하는데 필요한 지침을 마련\\nn(생성 AI 위험요소 ) ‘생성 AI 프로파일 (NIST AI 600-1)’ 은 NIST의 ‘AI 위험관리 프레임워크 (AI \\nRMF)’ 사용자를 대상으로 생성 AI로 인한 위험을 식별하는 방법 및 조직 목표와 우선순위에 \\n걸맞은 위험 관리 조치를 안내\\n∙동 지침은 멀웨어 코딩, 사이버 공격 자동화 , 허위정보 유포, 사회공학 공격, 환각 등 생성 AI와 관련된 \\n13개 위험 요소와 이를 완화할 수 있는 조치를 제시\\nn(학습 데이터 위험) ‘생성 AI 및 이중용도 기반모델용 보안 소프트웨어 개발관행 (SP 800-218A)’ \\n문서는 NIST의 ‘보안 소프트웨어 개발 프레임워크 (SSDF)’ 를 보완해 악성 데이터의 위험 해결을 지원\\n∙동 지침은 AI 시스템 학습을 위한 데이터 수집 프로세스에 대한 권장사항을 제공하고 , 데이터 중독과 \\n편향, 변조 가능성을 파악할 수 있도록 학습 데이터에 대한 분석을 권고\\nn(합성 콘텐츠 위험) ‘합성 콘텐츠로 인한')]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_retriever.invoke(qa_df[\"question\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_retriever.invoke(qa_df[\"question\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import EnsembleRetriever\n",
    "\n",
    "retriever = EnsembleRetriever(\n",
    "    retrievers=[bm25_retriever, vector_retriever],\n",
    "    weights=[0.7, 0.3],\n",
    "    search_type=\"mmr\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"단락을 읽고 질문에 답하세요.\n",
    "\n",
    "# 질문\n",
    "{query} \n",
    "\n",
    "# 단락\n",
    "{retrieved_contents} \n",
    "\n",
    "# 답변\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "\n",
    "def get_rag_chain(model=\"gemma2\"):\n",
    "    return (\n",
    "        {\n",
    "            \"retrieved_contents\": retriever,\n",
    "            \"query\": RunnablePassthrough(),\n",
    "        }\n",
    "        | prompt\n",
    "        | ChatOllama(model=model, temperature=0.1)\n",
    "        | StrOutputParser()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "def get_data_generator(qa_df: DataFrame, model=\"gemma2\") -> Dataset:\n",
    "    llm = get_rag_chain(model)\n",
    "    qa_df[\"answer\"] = qa_df[\"question\"].apply(lambda x: llm.invoke(x))\n",
    "    qa_df[\"contexts\"] = qa_df[\"question\"].apply(\n",
    "        lambda x: [d.page_content for d in retriever.invoke(x)]\n",
    "    )\n",
    "    return qa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "nest_asyncio.apply()\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.metrics import (\n",
    "    faithfulness,\n",
    "    answer_relevancy,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    ")\n",
    "from ragas import RunConfig, evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_upstage import UpstageEmbeddings\n",
    "\n",
    "\n",
    "langchain_llm = LangchainLLMWrapper(\n",
    "    # ChatGoogleGenerativeAI(\n",
    "    #     model=\"gemini-1.5-pro\",\n",
    "    #     temperature=0,\n",
    "    #     max_tokens=None,\n",
    "    #     timeout=None,\n",
    "    #     max_retries=50,\n",
    "    # ),\n",
    "    ChatOpenAI(\n",
    "        model=\"gpt-4o\",\n",
    "        temperature=0.1,\n",
    "        max_tokens=None,\n",
    "        timeout=None,\n",
    "        max_retries=50,\n",
    "    ),\n",
    "    RunConfig(\n",
    "        timeout=None,\n",
    "        max_retries=50,\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n",
    "# embeddings = UpstageEmbeddings(model=\"solar-embedding-1-large\")\n",
    "model_name = \"BAAI/bge-m3\"\n",
    "model_kwargs = {\"device\": \"mps\"}\n",
    "encode_kwargs = {\"normalize_embeddings\": False}\n",
    "embeddings = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs,\n",
    ")\n",
    "\n",
    "\n",
    "def ragas_evaluate(dataset: Dataset):\n",
    "    metrics = [\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        context_precision,\n",
    "    ]\n",
    "\n",
    "    for m in metrics:\n",
    "        m.__setattr__(\"llm\", langchain_llm)\n",
    "        if hasattr(m, \"embeddings\"):\n",
    "            m.__setattr__(\"embeddings\", embeddings)\n",
    "\n",
    "    return evaluate(\n",
    "        dataset,\n",
    "        metrics=metrics,\n",
    "        raise_exceptions=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>ground_truth</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>오픈AI의 슈퍼 얼라인먼트 팀이 해체된 이유는 무엇인가요?</td>\n",
       "      <td>오픈AI의 슈퍼 얼라인먼트 팀이 해체된 이유는 얼라인먼트 팀이 안전 연구에 소홀해질...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>모델 성능이 최대 수준에 도달하기 위해 어떤 조건이 충족되어야 하는가?</td>\n",
       "      <td>모델 성능이 최대 수준에 도달하기 위해서는 컨텍스트 창 내의 예제가 수십만 개 토큰...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AI안전보안이사회는 어떤 목적으로 설립되었나요?</td>\n",
       "      <td>AI안전보안이사회는 국토안보부가 관할하는 주요 기반시설에서 AI의 안전하고 책임있는...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AI 자율제조 테스트 베드를 구축하는 목적은 무엇인가요?</td>\n",
       "      <td>AI 자율제조 테스트 베드를 구축하는 목적은 기업들이 AI 자율제조 시스템 구축 과...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>구글 딥마인드가 어떤 방법을 이용하여 LLM의 성능을 향상시키는 연구를 진행했나요?</td>\n",
       "      <td>구글 딥마인드는 '상황 내 학습(ICL)'을 이용해 미세조정 없이 LLM의 성능을 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>네이버가 2024년에 어떤 신규 모델을 출시했나요?</td>\n",
       "      <td>네이버는 2024 년에 '대시(HCX-DASH)' 모델을 출시했습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>미국 기업의 AI 사용률은 어떻게 변화했나요?</td>\n",
       "      <td>미국 기업의 AI 사용률은 2023년 9월 3.7%에서 2024년 2월에 5.4%로...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GPT-4o는 어떤 성능을 보여주었나요?</td>\n",
       "      <td>GPT-4o는 GPT-4 터보와 동일한 성능을 보여주었으며, 다국어, 오디오, 이미...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>GPT-4o의 응답시간은 어떻게 되나요?</td>\n",
       "      <td>GPT-4o의 응답시간은 최소 0.23초, 평균 0.32초입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>'합성 콘텐츠로 인한 위험 감소(NIST AI 100-4)' 지침은 무엇을 안내하고...</td>\n",
       "      <td>'합성 콘텐츠로 인한 위험 감소(NIST AI 100-4)' 지침은 AI로 생성되거...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question  \\\n",
       "9                    오픈AI의 슈퍼 얼라인먼트 팀이 해체된 이유는 무엇인가요?   \n",
       "27            모델 성능이 최대 수준에 도달하기 위해 어떤 조건이 충족되어야 하는가?   \n",
       "15                         AI안전보안이사회는 어떤 목적으로 설립되었나요?   \n",
       "19                    AI 자율제조 테스트 베드를 구축하는 목적은 무엇인가요?   \n",
       "8      구글 딥마인드가 어떤 방법을 이용하여 LLM의 성능을 향상시키는 연구를 진행했나요?   \n",
       "7                        네이버가 2024년에 어떤 신규 모델을 출시했나요?   \n",
       "17                          미국 기업의 AI 사용률은 어떻게 변화했나요?   \n",
       "4                              GPT-4o는 어떤 성능을 보여주었나요?   \n",
       "21                             GPT-4o의 응답시간은 어떻게 되나요?   \n",
       "24  '합성 콘텐츠로 인한 위험 감소(NIST AI 100-4)' 지침은 무엇을 안내하고...   \n",
       "\n",
       "                                         ground_truth  \n",
       "9   오픈AI의 슈퍼 얼라인먼트 팀이 해체된 이유는 얼라인먼트 팀이 안전 연구에 소홀해질...  \n",
       "27  모델 성능이 최대 수준에 도달하기 위해서는 컨텍스트 창 내의 예제가 수십만 개 토큰...  \n",
       "15  AI안전보안이사회는 국토안보부가 관할하는 주요 기반시설에서 AI의 안전하고 책임있는...  \n",
       "19  AI 자율제조 테스트 베드를 구축하는 목적은 기업들이 AI 자율제조 시스템 구축 과...  \n",
       "8   구글 딥마인드는 '상황 내 학습(ICL)'을 이용해 미세조정 없이 LLM의 성능을 ...  \n",
       "7             네이버는 2024 년에 '대시(HCX-DASH)' 모델을 출시했습니다.  \n",
       "17  미국 기업의 AI 사용률은 2023년 9월 3.7%에서 2024년 2월에 5.4%로...  \n",
       "4   GPT-4o는 GPT-4 터보와 동일한 성능을 보여주었으며, 다국어, 오디오, 이미...  \n",
       "21               GPT-4o의 응답시간은 최소 0.23초, 평균 0.32초입니다.  \n",
       "24  '합성 콘텐츠로 인한 위험 감소(NIST AI 100-4)' 지침은 AI로 생성되거...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_df = qa_df.sample(10)\n",
    "qa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29dc5c6978a94289bf61d01b627d2a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'faithfulness': 0.8364, 'answer_relevancy': 0.2980, 'context_recall': 0.9000, 'context_precision': 0.8000}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma2_df = ragas_evaluate(\n",
    "    Dataset.from_pandas(get_data_generator(qa_df, model=\"gemma2\"))\n",
    ")\n",
    "gemma2_df.to_pandas().to_parquet(\"gemma2.parquet\")\n",
    "gemma2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcdceaf2dd044cc8772761d38e63855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qwen2_df = ragas_evaluate(Dataset.from_pandas(get_data_generator(qa_df, model=\"qwen2\")))\n",
    "qwen2_df.to_pandas().to_parquet(\"qwen2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d411ebb3f544444a7ff37078c6bdf6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mistral_df = ragas_evaluate(\n",
    "    Dataset.from_pandas(get_data_generator(qa_df, model=\"mistral\"))\n",
    ")\n",
    "mistral_df.to_pandas().to_parquet(\"mistral.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de91a41950f6437886a0aff1db45ef4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eeve_df = ragas_evaluate(\n",
    "    Dataset.from_pandas(get_data_generator(qa_df, model=\"EEVE-Korean-10.8B\"))\n",
    ")\n",
    "eeve_df.to_pandas().to_parquet(\"eeve.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Gemma2</th>\n",
       "      <th>Qwen2</th>\n",
       "      <th>Mistral</th>\n",
       "      <th>EEVE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>faithfulness</td>\n",
       "      <td>0.836372</td>\n",
       "      <td>0.757908</td>\n",
       "      <td>0.914544</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>answer_relevancy</td>\n",
       "      <td>0.297962</td>\n",
       "      <td>0.313162</td>\n",
       "      <td>0.345320</td>\n",
       "      <td>0.500535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>context_recall</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>context_precision</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Metric    Gemma2     Qwen2   Mistral      EEVE\n",
       "0       faithfulness  0.836372  0.757908  0.914544  0.916667\n",
       "1   answer_relevancy  0.297962  0.313162  0.345320  0.500535\n",
       "2     context_recall  0.900000  0.800000  0.800000  0.800000\n",
       "3  context_precision  0.800000  0.800000  0.800000  0.800000"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result = pd.merge(\n",
    "    pd.merge(\n",
    "        pd.DataFrame(list(gemma2_df.items()), columns=[\"Metric\", \"Gemma2\"]),\n",
    "        pd.DataFrame(list(qwen2_df.items()), columns=[\"Metric\", \"Qwen2\"]),\n",
    "        on=\"Metric\",\n",
    "    ),\n",
    "    pd.merge(\n",
    "        pd.DataFrame(list(mistral_df.items()), columns=[\"Metric\", \"Mistral\"]),\n",
    "        pd.DataFrame(list(eeve_df.items()), columns=[\"Metric\", \"EEVE\"]),\n",
    "        on=\"Metric\",\n",
    "    ),\n",
    "    on=\"Metric\",\n",
    ")\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autorag-tutorial-ko-sf4p_dcK-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
